{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tts_models/multilingual/multi-dataset/xtts_v2', 'tts_models/multilingual/multi-dataset/xtts_v1.1', 'tts_models/multilingual/multi-dataset/your_tts', 'tts_models/multilingual/multi-dataset/bark', 'tts_models/bg/cv/vits', 'tts_models/cs/cv/vits', 'tts_models/da/cv/vits', 'tts_models/et/cv/vits', 'tts_models/ga/cv/vits', 'tts_models/en/ek1/tacotron2', 'tts_models/en/ljspeech/tacotron2-DDC', 'tts_models/en/ljspeech/tacotron2-DDC_ph', 'tts_models/en/ljspeech/glow-tts', 'tts_models/en/ljspeech/speedy-speech', 'tts_models/en/ljspeech/tacotron2-DCA', 'tts_models/en/ljspeech/vits', 'tts_models/en/ljspeech/vits--neon', 'tts_models/en/ljspeech/fast_pitch', 'tts_models/en/ljspeech/overflow', 'tts_models/en/ljspeech/neural_hmm', 'tts_models/en/vctk/vits', 'tts_models/en/vctk/fast_pitch', 'tts_models/en/sam/tacotron-DDC', 'tts_models/en/blizzard2013/capacitron-t2-c50', 'tts_models/en/blizzard2013/capacitron-t2-c150_v2', 'tts_models/en/multi-dataset/tortoise-v2', 'tts_models/en/jenny/jenny', 'tts_models/es/mai/tacotron2-DDC', 'tts_models/es/css10/vits', 'tts_models/fr/mai/tacotron2-DDC', 'tts_models/fr/css10/vits', 'tts_models/uk/mai/glow-tts', 'tts_models/uk/mai/vits', 'tts_models/zh-CN/baker/tacotron2-DDC-GST', 'tts_models/nl/mai/tacotron2-DDC', 'tts_models/nl/css10/vits', 'tts_models/de/thorsten/tacotron2-DCA', 'tts_models/de/thorsten/vits', 'tts_models/de/thorsten/tacotron2-DDC', 'tts_models/de/css10/vits-neon', 'tts_models/ja/kokoro/tacotron2-DDC', 'tts_models/tr/common-voice/glow-tts', 'tts_models/it/mai_female/glow-tts', 'tts_models/it/mai_female/vits', 'tts_models/it/mai_male/glow-tts', 'tts_models/it/mai_male/vits', 'tts_models/ewe/openbible/vits', 'tts_models/hau/openbible/vits', 'tts_models/lin/openbible/vits', 'tts_models/tw_akuapem/openbible/vits', 'tts_models/tw_asante/openbible/vits', 'tts_models/yor/openbible/vits', 'tts_models/hu/css10/vits', 'tts_models/el/cv/vits', 'tts_models/fi/css10/vits', 'tts_models/hr/cv/vits', 'tts_models/lt/cv/vits', 'tts_models/lv/cv/vits', 'tts_models/mt/cv/vits', 'tts_models/pl/mai_female/vits', 'tts_models/pt/cv/vits', 'tts_models/ro/cv/vits', 'tts_models/sk/cv/vits', 'tts_models/sl/cv/vits', 'tts_models/sv/cv/vits', 'tts_models/ca/custom/vits', 'tts_models/fa/custom/glow-tts', 'tts_models/bn/custom/vits-male', 'tts_models/bn/custom/vits-female', 'tts_models/be/common-voice/glow-tts', 'vocoder_models/universal/libri-tts/wavegrad', 'vocoder_models/universal/libri-tts/fullband-melgan', 'vocoder_models/en/ek1/wavegrad', 'vocoder_models/en/librispeech100/wavlm-hifigan', 'vocoder_models/en/librispeech100/wavlm-hifigan_prematched', 'vocoder_models/en/ljspeech/multiband-melgan', 'vocoder_models/en/ljspeech/hifigan_v2', 'vocoder_models/en/ljspeech/univnet', 'vocoder_models/en/blizzard2013/hifigan_v2', 'vocoder_models/en/vctk/hifigan_v2', 'vocoder_models/en/sam/hifigan_v2', 'vocoder_models/nl/mai/parallel-wavegan', 'vocoder_models/de/thorsten/wavegrad', 'vocoder_models/de/thorsten/fullband-melgan', 'vocoder_models/de/thorsten/hifigan_v1', 'vocoder_models/ja/kokoro/hifigan_v1', 'vocoder_models/uk/mai/multiband-melgan', 'vocoder_models/tr/common-voice/hifigan', 'vocoder_models/be/common-voice/hifigan', 'voice_conversion_models/multilingual/vctk/freevc24', 'voice_conversion_models/multilingual/multi-dataset/knnvc', 'voice_conversion_models/multilingual/multi-dataset/openvoice_v1', 'voice_conversion_models/multilingual/multi-dataset/openvoice_v2']\n",
      "['Claribel Dervla', 'Daisy Studious', 'Gracie Wise', 'Tammie Ema', 'Alison Dietlinde', 'Ana Florence', 'Annmarie Nele', 'Asya Anara', 'Brenda Stern', 'Gitta Nikolina', 'Henriette Usha', 'Sofia Hellen', 'Tammy Grit', 'Tanja Adelina', 'Vjollca Johnnie', 'Andrew Chipper', 'Badr Odhiambo', 'Dionisio Schuyler', 'Royston Min', 'Viktor Eka', 'Abrahan Mack', 'Adde Michal', 'Baldur Sanjin', 'Craig Gutsy', 'Damien Black', 'Gilberto Mathias', 'Ilkin Urbano', 'Kazuhiko Atallah', 'Ludvig Milivoj', 'Suad Qasim', 'Torcull Diarmuid', 'Viktor Menelaos', 'Zacharie Aimilios', 'Nova Hogarth', 'Maja Ruoho', 'Uta Obando', 'Lidiya Szekeres', 'Chandra MacFarland', 'Szofi Granger', 'Camilla Holmstr√∂m', 'Lilya Stainthorpe', 'Zofija Kendrick', 'Narelle Moon', 'Barbora MacLean', 'Alexandra Hisakawa', 'Alma Mar√≠a', 'Rosemary Okafor', 'Ige Behringer', 'Filip Traverse', 'Damjan Chapman', 'Wulf Carlevaro', 'Aaron Dreschner', 'Kumar Dahl', 'Eugenio Mataracƒ±', 'Ferran Simen', 'Xavier Hayasaka', 'Luis Moray', 'Marcos Rudaski']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "\n",
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# List available üê∏TTS models\n",
    "print(TTS().list_models())\n",
    "\n",
    "# Initialize TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "# List speakers\n",
    "print(tts.speakers)\n",
    "\n",
    "# Run TTS\n",
    "# ‚ùó XTTS supports both, but many models allow only one of the `speaker` and\n",
    "# `speaker_wav` arguments\n",
    "\n",
    "# TTS with list of amplitude values as output, clone the voice from `speaker_wav`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "\n",
    "def calculate_total_wav_length(directory_path):\n",
    "    \"\"\"\n",
    "    Calculate the total duration of all .wav files in the given directory.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing .wav files.\n",
    "\n",
    "    Returns:\n",
    "        int, int, int: Total duration (hours, minutes, seconds).\n",
    "    \"\"\"\n",
    "    total_duration = 0.0\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            try:\n",
    "                with wave.open(file_path, 'r') as audio_file:\n",
    "                    frames = audio_file.getnframes()\n",
    "                    rate = audio_file.getframerate()\n",
    "                    duration = frames / float(rate)\n",
    "                    total_duration += duration\n",
    "            except Exception as e:\n",
    "                print(f\"Could not process file {filename}: {e}\")\n",
    "    \n",
    "    # Convert total_duration from seconds to hours, minutes, seconds\n",
    "    hours, remainder = divmod(total_duration, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "    return int(hours), int(minutes), int(seconds)\n",
    "\n",
    "def get_highest_index(directory_path):\n",
    "    max_index = -1\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.startswith(\"text_\") and filename.endswith(\".txt\"):\n",
    "            try:\n",
    "                index = int(filename[5:-4])\n",
    "                max_index = max(max_index, index)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''–ö–æ–ª–ª–µ–≥–∏, –Ω–∞—á–Ω–µ–º —Å –∞–Ω–∞–ª–∏–∑–∞ –æ–±—ä–µ–º–æ–≤ –¥–æ–±—ã—á–∏, –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏ –∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ —É–≥–ª–µ–≤–æ–¥–æ—Ä–æ–¥–æ–≤ –∑–∞ –ø—Ä–æ—à–µ–¥—à–∏–π –∫–≤–∞—Ä—Ç–∞–ª. –°–æ–≥–ª–∞—Å–Ω–æ –æ—Ç—á–µ—Ç—É –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞, –æ–±—â–∏–π –æ–±—ä–µ–º –¥–æ–±—ã—á–∏ –Ω–µ—Ñ—Ç–∏ —Å–æ—Å—Ç–∞–≤–∏–ª 12,8 –º–ª–Ω —Ç–æ–Ω–Ω, —á—Ç–æ –Ω–∞ 3% –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ø–ª–∞–Ω–æ–≤—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å. –û–¥–Ω–∞–∫–æ –µ—Å—Ç—å –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –≤ –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–µ –Ω–∞ –¥–≤—É—Ö –∫–ª—é—á–µ–≤—ã—Ö –ù–ü–ó –∏–∑-–∑–∞ –Ω–µ–∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Å—Ç–æ–µ–≤ –Ω–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∞—Ö –≥–∏–¥—Ä–æ–∫—Ä–µ–∫–∏–Ω–≥–∞. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ–¥—Ö–æ–¥ –∫ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—é –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è. –ö—Ä–æ–º–µ —Ç–æ–≥–æ, —Ç–µ–∫—É—â–∏–µ –æ–±—ä–µ–º—ã —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ —Å–Ω–∏–∂–µ–Ω—ã –Ω–∞ 1,5% –∏–∑-–∑–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –Ω–∞ –æ–¥–Ω–æ–º –∏–∑ –º–∞–≥–∏—Å—Ç—Ä–∞–ª—å–Ω—ã—Ö —Ç—Ä—É–±–æ–ø—Ä–æ–≤–æ–¥–æ–≤. –ü—Ä–µ–¥–ª–∞–≥–∞—é —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–Ω–µ—à–Ω–∏—Ö –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ—Ç–æ–∫–æ–≤ –Ω–∞ –±–ª–∏–∂–∞–π—à–∏–π –º–µ—Å—è—Ü, —á—Ç–æ–±—ã –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–µ—Ä–∂–∫–∏ –ø–æ—Å—Ç–∞–≤–æ–∫.\n",
    "\n",
    "–ù–∞ –ø—Ä–æ—à–ª–æ–π –Ω–µ–¥–µ–ª–µ –º—ã –ø–æ–ª—É—á–∏–ª–∏ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–π –∫–æ–Ω—Å–∞–ª—Ç–∏–Ω–≥–æ–≤–æ–π –∫–æ–º–ø–∞–Ω–∏–∏ –æ –Ω–∞—à–µ–º —É–≥–ª–µ—Ä–æ–¥–Ω–æ–º —Å–ª–µ–¥–µ. –£—Ä–æ–≤–µ–Ω—å –≤—ã–±—Ä–æ—Å–æ–≤ CO2 –≤ –ø–µ—Ä–µ—Ä–∞—Å—á–µ—Ç–µ –Ω–∞ –±–∞—Ä—Ä–µ–ª—å –¥–æ–±—ã—Ç–æ–π –Ω–µ—Ñ—Ç–∏ –∑–∞ –≥–æ–¥ —Å–Ω–∏–∑–∏–ª—Å—è –Ω–∞ 2,3% –±–ª–∞–≥–æ–¥–∞—Ä—è –≤–≤–µ–¥–µ–Ω–∏—é —Å–∏—Å—Ç–µ–º—ã —É–ª–∞–≤–ª–∏–≤–∞–Ω–∏—è —É–≥–ª–µ–∫–∏—Å–ª–æ–≥–æ –≥–∞–∑–∞ –Ω–∞ –æ–¥–Ω–æ–º –∏–∑ –º–µ—Å—Ç–æ—Ä–æ–∂–¥–µ–Ω–∏–π –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —ç–Ω–µ—Ä–≥–æ–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è. –û–¥–Ω–∞–∫–æ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö KPI –∫ 2030 –≥–æ–¥—É –Ω–∞–º –Ω—É–∂–Ω–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–µ–∫—Ç—ã –ø–æ –≤–Ω–µ–¥—Ä–µ–Ω–∏—é –í–ò–≠, –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏, —É—Å–∫–æ—Ä–∏—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å–æ–ª–Ω–µ—á–Ω–æ–π –∏ –≤–µ—Ç—Ä—è–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É –∑–∞–ø–∞–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞. –¢–∞–∫–∂–µ –≤–∞–∂–Ω–æ –Ω–∞—á–∞—Ç—å –ø–∏–ª–æ—Ç–Ω—ã–π –ø—Ä–æ–µ–∫—Ç –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –≤–∏–¥–æ–≤ —Ç–æ–ø–ª–∏–≤–∞ –¥–ª—è –∞–≤—Ç–æ–ø–∞—Ä–∫–∞ –Ω–∞—à–∏—Ö –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π.\n",
    "\n",
    "–ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –∞–Ω–∞–ª–∏–∑—É —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–æ—â–Ω–æ—Å—Ç–µ–π. –¢—Ä—É–±–æ–ø—Ä–æ–≤–æ–¥–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ —É—á–∞—Å—Ç–∫–µ NORD-43 —Ç—Ä–µ–±—É–µ—Ç —Å—Ä–æ—á–Ω–æ–≥–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∞—É–¥–∏—Ç–∞ –ø–æ—Å–ª–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–æ—Ä—Ä–æ–∑–∏–π–Ω–æ–≥–æ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è –Ω–∞ –º–∞–≥–∏—Å—Ç—Ä–∞–ª—å–Ω–æ–º —Å–µ–≥–º–µ–Ω—Ç–µ. –≠—Ç–æ –º–æ–∂–µ—Ç –ø–æ–≤–ª–∏—è—Ç—å –Ω–∞ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—É—é –Ω–∞–≥—Ä—É–∑–∫—É –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏. –ü–æ–º–∏–º–æ —ç—Ç–æ–≥–æ, –æ–±—Å—É–∂–¥–∞–µ—Ç—Å—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–≤–æ–æ—Ä—É–∂–µ–Ω–∏—è –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä–Ω—ã—Ö —Å—Ç–∞–Ω—Ü–∏–π: —Ç–µ–∫—É—â–∏–µ –∞–≥—Ä–µ–≥–∞—Ç—ã —É–∂–µ –ø—Ä–µ–≤—ã—à–∞—é—Ç –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π —Å—Ä–æ–∫ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏. –ü—Ä–µ–¥–ª–∞–≥–∞—é –ø–æ–¥–∫–ª—é—á–∏—Ç—å –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç –≥–ª–∞–≤–Ω–æ–≥–æ –∏–Ω–∂–µ–Ω–µ—Ä–∞ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ —Å—Ä–æ–∫–∞–º –º–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏–∏ —Å —É—á–µ—Ç–æ–º –±—é–¥–∂–µ—Ç–∞ —Å–ª–µ–¥—É—é—â–µ–≥–æ –≥–æ–¥–∞. –ß—Ç–æ –∫–∞—Å–∞–µ—Ç—Å—è —Ü–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏–∏, –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –Ω–∞ —É—á–∞—Å—Ç–∫–µ EAST-12 –ø–æ–∑–≤–æ–ª–∏–ª–æ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –≤–Ω–µ–ø–ª–∞–Ω–æ–≤—ã–µ –ø—Ä–æ—Å—Ç–æ–∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –Ω–∞ 15%. –ù–∞–¥–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –¥–∞–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ –Ω–∞ –¥—Ä—É–≥–∏–µ —É—á–∞—Å—Ç–∫–∏.\n",
    "\n",
    "–°–æ–≥–ª–∞—Å–Ω–æ –¥–∞–Ω–Ω—ã–º –≥–µ–æ–ª–æ–≥–æ—Ä–∞–∑–≤–µ–¥–∫–∏ —Ç–µ–∫—É—â–µ–≥–æ –≥–æ–¥–∞, –∑–∞–≤–µ—Ä—à–µ–Ω—ã —Å–µ–π—Å–º–∏—á–µ—Å–∫–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –Ω–∞ –±–ª–æ–∫–µ ZETA-9. –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∑–∞–ø–∞—Å—ã —É–≥–ª–µ–≤–æ–¥–æ—Ä–æ–¥–æ–≤ –æ—Ü–µ–Ω–∏–≤–∞—é—Ç—Å—è –≤ 450 –º–ª–Ω —Ç–æ–Ω–Ω –∏–∑–≤–ª–µ–∫–∞–µ–º—ã—Ö —Ä–µ–∑–µ—Ä–≤–æ–≤, —á—Ç–æ, –ø–æ –Ω–∞—à–µ–º—É –º–Ω–µ–Ω–∏—é, —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–Ω–æ–π –±–∞–∑—ã –∫–æ–º–ø–∞–Ω–∏–∏. –†–µ–∫–æ–º–µ–Ω–¥—É—é —É—Å–∫–æ—Ä–∏—Ç—å –Ω–∞—á–∞–ª–æ –±—É—Ä–æ–≤—ã—Ö —Ä–∞–±–æ—Ç –Ω–∞ —ç—Ç–æ–º —É—á–∞—Å—Ç–∫–µ, —Ç–∞–∫ –∫–∞–∫ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ —Ä–µ–≥–∏–æ–Ω–µ —É—Å–∏–ª–∏–≤–∞–µ—Ç—Å—è. –ö—Ä–æ–º–µ —Ç–æ–≥–æ, –Ω–∞ –±–ª–æ–∫–µ ALFA-4 –ø—Ä–æ–±—É—Ä–µ–Ω–∞ –ø–µ—Ä–≤–∞—è –ø–æ–∏—Å–∫–æ–≤–∞—è —Å–∫–≤–∞–∂–∏–Ω–∞, —Ç–µ–∫—É—â–∏–π –¥–µ–±–∏—Ç —Å–æ—Å—Ç–∞–≤–∏–ª 320 –±–∞—Ä—Ä–µ–ª–µ–π –≤ —Å—É—Ç–∫–∏. –≠—Ç–æ –æ–±–Ω–∞–¥–µ–∂–∏–≤–∞—é—â–∏–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å, –∫–æ—Ç–æ—Ä—ã–π —Ç—Ä–µ–±—É–µ—Ç –≤–æ–≤–ª–µ—á–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–∏—Ö –±—É—Ä–æ–≤—ã—Ö —Ä–∞–±–æ—Ç –∏ —Ä–∞–∑–≤–∏—Ç–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤—É–∞—Ä–æ–≤.\n",
    "\n",
    "–ü–æ –∏—Ç–æ–≥–∞–º –≤—Ç–æ—Ä–æ–≥–æ –ø–æ–ª—É–≥–æ–¥–∏—è, –≤—ã—Ä—É—á–∫–∞ –∫–æ–º–ø–∞–Ω–∏–∏ —É–≤–µ–ª–∏—á–∏–ª–∞—Å—å –Ω–∞ 8% –±–ª–∞–≥–æ–¥–∞—Ä—è –±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω–æ–π –∫–æ–Ω—ä—é–Ω–∫—Ç—É—Ä–µ –Ω–∞ –º–∏—Ä–æ–≤–æ–º —Ä—ã–Ω–∫–µ –Ω–µ—Ñ—Ç–∏. –¢–µ–º –Ω–µ –º–µ–Ω–µ–µ, –µ—Å—Ç—å —Ä—è–¥ –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–º –∑–∞—Ç—Ä–∞—Ç–∞–º. –£–¥–µ–ª—å–Ω—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã –Ω–∞ –¥–æ–±—ã—á—É –≤ –≤–æ—Å—Ç–æ—á–Ω–æ–º —Ä–µ–≥–∏–æ–Ω–µ –ø—Ä–µ–≤—ã—à–∞—é—Ç —Å—Ä–µ–¥–Ω–∏–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –∫–æ–º–ø–∞–Ω–∏–∏ –Ω–∞ 12% –∏–∑-–∑–∞ —Å–ª–æ–∂–Ω—ã—Ö –≥–µ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —É—Å–ª–æ–≤–∏–π. –í —ç—Ç–æ–π —Å–≤—è–∑–∏ –≤–∞–∂–Ω–æ –∑–∞–≤–µ—Ä—à–∏—Ç—å –∞—É–¥–∏—Ç —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ä–∞—Å—Ö–æ–¥–æ–≤ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –º–µ—Ä—ã –ø–æ –ø–æ–≤—ã—à–µ–Ω–∏—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏. –¢–∞–∫–∂–µ –æ—Å—Ç–∞–µ—Ç—Å—è –∑–∞–¥–∞—á–∞ —Å–Ω–∏–∂–µ–Ω–∏—è –∑–∞—Ç—Ä–∞—Ç –Ω–∞ –ª–æ–≥–∏—Å—Ç–∏–∫—É: –ø—Ä–µ–¥–ª–∞–≥–∞—é –æ–±—Å—É–¥–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤ —á–µ—Ä–µ–∑ –µ–¥–∏–Ω—ã–π —Ü–µ–Ω—Ç—Ä —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–∫—É–ø–∫–∞–º–∏. –û—Ç–¥–µ–ª—å–Ω–æ —Å—Ç–æ–∏—Ç –æ—Ç–º–µ—Ç–∏—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∫–∞–ø–∑–∞—Ç—Ä–∞—Ç –Ω–∞ –º–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—é, –æ —á–µ–º —É–ø–æ–º–∏–Ω–∞–ª–æ—Å—å —Ä–∞–Ω–µ–µ.\n",
    "\n",
    "–î–∞–≤–∞–π—Ç–µ –æ–±—Å—É–¥–∏–º –≤–æ–∑–Ω–∏–∫–∞—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏–º –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞ –¥–∞–ª—å–Ω–µ–π—à–µ–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–µ—à–µ–Ω–∏–π –ø–æ –∫–∞–∂–¥–æ–º—É –∏–∑ –±–ª–æ–∫–æ–≤.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"–î–æ—Ä–æ–≥–∏–µ –∫–æ–ª–ª–µ–≥–∏, —Ä–∞–¥ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –≤–∞—Å –Ω–∞ —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–º —Å–æ–≤–µ—â–∞–Ω–∏–∏. –ù–∞—à–∞ –≤—Å—Ç—Ä–µ—á–∞ –ø–æ—Å–≤—è—â–µ–Ω–∞ —Ç—Ä–µ–º –≤–∞–∂–Ω—ã–º —Ç–µ–º–∞–º: —Ä–∞–∑–≤–∏—Ç–∏—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –∏ —Ü–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –≤ –∫–æ–º–ø–∞–Ω–∏–∏, —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é —Ä–∏—Å–∫–∞–º–∏ –≤ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞—Ö –∏ —É—á–∞—Å—Ç–∏—é –≤ —Ç–µ–Ω–¥–µ—Ä–∞—Ö, –≤–∫–ª—é—á–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É —Ç–µ–Ω–¥–µ—Ä–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏. –í –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Ä–∞–∑–≤–∏—Ç–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –∏ —Ü–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –º—ã —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏–º—Å—è –Ω–∞ –≤–Ω–µ–¥—Ä–µ–Ω–∏–∏ –ø–µ—Ä–µ–¥–æ–≤—ã—Ö —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤. –ò—Å—Å–ª–µ–¥—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ–±–ª–∞—á–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã–º–∏ –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏. –í –±–ª–∏–∂–∞–π—à–µ–º –±—É–¥—É—â–µ–º –≤–∞–∂–Ω–æ –±—É–¥–µ—Ç —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤. –í—Ç–æ—Ä–∞—è —Ç–µ–º–∞ –ø–æ–≤–µ—Å—Ç–∫–∏ –∫–∞—Å–∞–µ—Ç—Å—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∏—Å–∫–∞–º–∏ –≤ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞—Ö. –†–∏—Å–∫–∏ –Ω–µ–∏–∑–±–µ–∂–Ω—ã, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –∏ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ–π —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏. –ú—ã –æ–±—Å—É–¥–∏–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –Ω–∞ –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—é –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —É–≥—Ä–æ–∑, –≤–∫–ª—é—á–∞—è –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤, –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–≥–æ –∞—É–¥–∏—Ç–∞ –ø—Ä–æ–µ–∫—Ç–æ–≤ –∏ –Ω–∞–ª–∏—á–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –¥–µ–π—Å—Ç–≤–∏–π –Ω–∞ —Å–ª—É—á–∞–π —Ñ–æ—Ä—Å-–º–∞–∂–æ—Ä–Ω—ã—Ö –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤. –ö—Ä–æ–º–µ —Ç–æ–≥–æ, —É–¥–µ–ª–∏–º –≤–Ω–∏–º–∞–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞–º –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∏—Å–∫–æ–≤ –∏ –∫–∞–∫ –æ–Ω–∏ –º–æ–≥—É—Ç –ø–æ–≤–ª–∏—è—Ç—å –Ω–∞ –Ω–∞—à–∏ –ø—Ä–æ–µ–∫—Ç—ã –≤ —Ä–∞–∑–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–∞—Ö –º–∏—Ä–∞. –ü–µ—Ä–µ—Ö–æ–¥—è –∫ —Ç—Ä–µ—Ç—å–µ–π —Ç–µ–º–µ –Ω–∞—à–∏—Ö –æ–±—Å—É–∂–¥–µ–Ω–∏–π, –º—ã –∫–æ—Å–Ω–µ–º—Å—è —É—á–∞—Å—Ç–∏—è –≤ —Ç–µ–Ω–¥–µ—Ä–∞—Ö –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Ç–µ–Ω–¥–µ—Ä–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏. –ù–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É—Å–∏–ª–∏—Ç—å –Ω–∞—à—É –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –Ω–∞ —ç—Ç–æ–º —Ñ—Ä–æ–Ω—Ç–µ, –æ–±–µ—Å–ø–µ—á–∏–≤ –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–∞—à–µ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º. –†–∞–±–æ—Ç–∞ –Ω–∞ —ç—Ç–∞–ø–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–Ω–¥–µ—Ä–∞, –∞ —Ç–∞–∫–∂–µ —á–µ—Ç–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∏ —É—Å–ª–æ–≤–∏–π –±—É–¥—É—Ç –∫–ª—é—á–µ–≤—ã–º–∏ —Ñ–∞–∫—Ç–æ—Ä–∞–º–∏ –¥–ª—è —É—Å–ø–µ—à–Ω–æ–≥–æ —É—á–∞—Å—Ç–∏—è. –ú—ã —Ç–∞–∫–∂–µ –æ–±—Å—É–¥–∏–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —ç—Ç–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤, —á—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç –Ω–∞–º —É—Å–∫–æ—Ä–∏—Ç—å –ø–æ–¥–∞—á—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏ –ø–æ–≤—ã—Å–∏—Ç—å –∏—Ö –∫–∞—á–µ—Å—Ç–≤–æ. –†–∞—Å—Å–º–æ—Ç—Ä–∏–º —Ç–∞–∫–∂–µ –≤–∞–∂–Ω–æ—Å—Ç—å —Å–æ–±–ª—é–¥–µ–Ω–∏—è –ø—Ä–∞–≤–æ–≤—ã—Ö –Ω–æ—Ä–º –∏ –Ω–∞–ª–∏—á–∏—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤ –≤ –æ–±–ª–∞—Å—Ç–∏ –Ω–∞–ª–æ–≥–æ–≤–æ–≥–æ –∏ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–Ω–æ–≥–æ –ø—Ä–∞–≤–∞. –°–ø–∞—Å–∏–±–æ –∑–∞ –≤–Ω–∏–º–∞–Ω–∏–µ, –∏ –Ω–∞–¥–µ—é—Å—å –Ω–∞ –ø–ª–æ–¥–æ—Ç–≤–æ—Ä–Ω–æ–µ –æ–±—Å—É–∂–¥–µ–Ω–∏–µ –ø–æ –∫–∞–∂–¥–æ–π –∏–∑ —Ç–µ–º —Å–µ–≥–æ–¥–Ω—è.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"test_dataset_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dir = Path(f\"./outputs/{dataset_name}/text\")\n",
    "speech_dir = Path(f\"./outputs/{dataset_name}/speech\")\n",
    "\n",
    "text_dir.mkdir(parents=True, exist_ok=True)\n",
    "speech_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next index: 65\n"
     ]
    }
   ],
   "source": [
    "index = get_highest_index(text_dir.absolute()) + 1\n",
    "print(f\"Next index: {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "  5%|‚ñå         | 1/20 [01:42<32:30, 102.68s/it]The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      " 10%|‚ñà         | 2/20 [03:30<31:39, 105.50s/it]The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      " 15%|‚ñà‚ñå        | 3/20 [05:25<31:11, 110.10s/it]The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      " 20%|‚ñà‚ñà        | 4/20 [06:47<26:21, 98.84s/it] The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      " 25%|‚ñà‚ñà‚ñå       | 5/20 [08:12<23:26, 93.79s/it]The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      " 30%|‚ñà‚ñà‚ñà       | 6/20 [10:05<23:25, 100.40s/it]The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      " 35%|‚ñà‚ñà‚ñà‚ñå      | 7/20 [11:46<21:46, 100.50s/it]The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 8/20 [13:01<18:30, 92.53s/it] The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 10/20 [16:21<16:01, 96.20s/it]The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 11/20 [17:47<13:56, 92.91s/it]The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 12/20 [19:13<12:07, 90.95s/it]The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 14/20 [22:12<08:51, 88.62s/it]The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 15/20 [23:38<07:19, 87.89s/it]The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 16/20 [25:01<05:45, 86.35s/it]The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 17/20 [26:44<04:34, 91.36s/it]The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 18/20 [28:29<03:10, 95.50s/it]The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 19/20 [30:16<01:39, 99.07s/it]The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [32:11<00:00, 96.59s/it] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('table_dsv.json', 'r') as file:\n",
    "    for text in tqdm(file.readlines()):\n",
    "        text = re.sub('\\n', \" \", text)\n",
    "        text = re.sub(\"[!?;]\", \".\", text)\n",
    "        text = re.sub(r'\\s+', \" \", text)\n",
    "\n",
    "        text = text.split(\"suffix=\")[1].split(\"text_id\")[0].strip()\n",
    "        \n",
    "        for sentence in text.split(\". \"):\n",
    "            with open(f'outputs/{dataset_name}/text/text_{index}.txt', 'w') as output:\n",
    "                output.write(sentence)\n",
    "            tts.tts_to_file(\n",
    "                text=sentence,\n",
    "                speaker=random.choice(tts.speakers),\n",
    "                language=\"ru\",\n",
    "                file_path=f\"outputs/{dataset_name}/speech/speech_{index}.wav\"\n",
    "            )\n",
    "            index += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration of all .wav files: 0 hours, 59 minutes, 40 seconds\n"
     ]
    }
   ],
   "source": [
    "hours, minutes, seconds = calculate_total_wav_length(speech_dir.absolute())\n",
    "print(f\"Total duration of all .wav files: {hours} hours, {minutes} minutes, {seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 182 for language 'ru', this might cause truncated audio.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m wav \u001b[38;5;241m=\u001b[39m \u001b[43mtts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43mspeaker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCraig Gutsy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m  \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mru\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m display(Audio(wav, rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24000\u001b[39m))\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/TTS/api.py:323\u001b[0m, in \u001b[0;36mTTS.tts\u001b[0;34m(self, text, speaker, language, speaker_wav, emotion, speed, split_sentences, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert text to speech.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03m        Additional arguments for the model.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_arguments(\n\u001b[1;32m    321\u001b[0m     speaker\u001b[38;5;241m=\u001b[39mspeaker, language\u001b[38;5;241m=\u001b[39mlanguage, speaker_wav\u001b[38;5;241m=\u001b[39mspeaker_wav, emotion\u001b[38;5;241m=\u001b[39memotion, speed\u001b[38;5;241m=\u001b[39mspeed, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    322\u001b[0m )\n\u001b[0;32m--> 323\u001b[0m wav \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeaker_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlanguage_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_sentences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_sentences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wav\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py:422\u001b[0m, in \u001b[0;36mSynthesizer.tts\u001b[0;34m(self, text, speaker_name, language_name, speaker_wav, style_wav, style_text, reference_wav, reference_speaker_name, split_sentences, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m sens:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynthesize\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 422\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspeaker_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvoice_dirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvoice_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m            \u001b[49m\u001b[43md_vector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;66;03m# synthesize voice\u001b[39;00m\n\u001b[1;32m    434\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m synthesis(\n\u001b[1;32m    435\u001b[0m             model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_model,\n\u001b[1;32m    436\u001b[0m             text\u001b[38;5;241m=\u001b[39msen,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m             language_id\u001b[38;5;241m=\u001b[39mlanguage_id,\n\u001b[1;32m    445\u001b[0m         )\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/TTS/tts/models/xtts.py:397\u001b[0m, in \u001b[0;36mXtts.synthesize\u001b[0;34m(self, text, config, speaker_wav, language, speaker_id, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m speaker_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    396\u001b[0m     gpt_cond_latent, speaker_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeaker_manager\u001b[38;5;241m.\u001b[39mspeakers[speaker_id]\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpt_cond_latent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeaker_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m settings\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    399\u001b[0m     {\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt_cond_len\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mgpt_cond_len,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    404\u001b[0m     }\n\u001b[1;32m    405\u001b[0m )\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull_inference(text, speaker_wav, language, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings)\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/TTS/tts/models/xtts.py:528\u001b[0m, in \u001b[0;36mXtts.inference\u001b[0;34m(self, text, language, gpt_cond_latent, speaker_embedding, temperature, length_penalty, repetition_penalty, top_k, top_p, do_sample, num_beams, speed, enable_text_splitting, **hf_generate_kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    524\u001b[0m     text_tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgpt_max_text_tokens\n\u001b[1;32m    525\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ‚ùó XTTS can only generate text with a maximum of 400 tokens.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 528\u001b[0m     gpt_codes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcond_latents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpt_cond_latent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpt_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_beams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlength_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhf_generate_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m     expected_output_len \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    544\u001b[0m         [gpt_codes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpt\u001b[38;5;241m.\u001b[39mcode_stride_len], device\u001b[38;5;241m=\u001b[39mtext_tokens\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    545\u001b[0m     )\n\u001b[1;32m    547\u001b[0m     text_len \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([text_tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/gpt.py:512\u001b[0m, in \u001b[0;36mGPT.generate\u001b[0;34m(self, cond_latents, text_inputs, **hf_generate_kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m stop_token_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_audio_token, device\u001b[38;5;241m=\u001b[39mgpt_inputs\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m    511\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m _prepare_attention_mask_for_generation(gpt_inputs, stop_token_tensor, stop_token_tensor)\n\u001b[0;32m--> 512\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpt_inference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_audio_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop_audio_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop_audio_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_gen_mel_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgpt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhf_generate_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict_in_generate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m hf_generate_kwargs:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gen\u001b[38;5;241m.\u001b[39msequences[:, gpt_inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] :], gen\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/transformers/generation/utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2212\u001b[0m     )\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2235\u001b[0m     )\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/transformers/generation/utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3210\u001b[0m     outputs,\n\u001b[1;32m   3211\u001b[0m     model_kwargs,\n\u001b[1;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3213\u001b[0m )\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/gpt_inference.py:98\u001b[0m, in \u001b[0;36mGPT2InferenceModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m     94\u001b[0m     emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids)\n\u001b[1;32m     95\u001b[0m     emb \u001b[38;5;241m=\u001b[39m emb \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embedding\u001b[38;5;241m.\u001b[39mget_fixed_embedding(\n\u001b[1;32m     96\u001b[0m         attention_mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m (prefix_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), attention_mask\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     97\u001b[0m     )\n\u001b[0;32m---> 98\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    113\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1132\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1121\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1122\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         output_attentions,\n\u001b[1;32m   1130\u001b[0m     )\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:615\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    613\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    614\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 615\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    624\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/tts/venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:503\u001b[0m, in \u001b[0;36mGPT2SdpaAttention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    486\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[1;32m    487\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`GPT2SdpaAttention` is used but `torch.nn.functional.scaled_dot_product_attention` does not support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    489\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecifying the manual implementation will be required from Transformers version v5.0.0 onwards. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis warning can be removed using the argument `attn_implementation=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m` when loading the model.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    491\u001b[0m     )\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    493\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    494\u001b[0m         layer_past\u001b[38;5;241m=\u001b[39mlayer_past,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    500\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    501\u001b[0m     )\n\u001b[0;32m--> 503\u001b[0m bsz, q_len, _ \u001b[38;5;241m=\u001b[39m \u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# Initial attention projections\u001b[39;00m\n\u001b[1;32m    506\u001b[0m is_cross_attention \u001b[38;5;241m=\u001b[39m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "wav = tts.tts(\n",
    "  text=text,\n",
    "  speaker=\"Craig Gutsy\",\n",
    "  language=\"ru\"\n",
    ")\n",
    "\n",
    "display(Audio(wav, rate=24000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputs/output_ru.wav'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wav = tts.tts(\n",
    "#   text=\"Hello world!\",\n",
    "#   language=\"en\"\n",
    "# )\n",
    "\n",
    "# TTS to a file, use a preset speaker\n",
    "tts.tts_to_file(\n",
    "  text=\"–¥–∞–≤–∞–π—Ç–µ –≤—Å–µ—Ö –∏—Ö –∑–∞–±–∞–Ω–∏–º –≤—Å–µ —Ä–∞–≤–Ω–æ –Ω–∏—á–µ–≥–æ —É –Ω–∞—Å –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç\",\n",
    "  speaker=\"Craig Gutsy\",\n",
    "  language=\"ru\",\n",
    "  file_path=\"outputs/output_ru.wav\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–î–æ–±—Ä–æ–µ —É—Ç—Ä–æ, —É–≤–∞–∂–∞–µ–º—ã–µ –∫–æ–ª–ª–µ–≥–∏', '–°–µ–≥–æ–¥–Ω—è —É –Ω–∞—Å –Ω–∞ –ø–æ–≤–µ—Å—Ç–∫–µ –¥–Ω—è —á–µ—Ç—ã—Ä–µ –∫–ª—é—á–µ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–∞, –∫–æ—Ç–æ—Ä—ã–µ —Ç—Ä–µ–±—É—é—Ç –Ω–∞—à–µ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è –∏ –æ–±—Å—É–∂–¥–µ–Ω–∏—è', '–ü–µ—Ä–≤—ã–π –≤–æ–ø—Ä–æ—Å –∫–∞—Å–∞–µ—Ç—Å—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–ø–∞—Å–∞–º–∏ –∏ —Å–∫–ª–∞–¥—Å–∫–∏–º —Ö–æ–∑—è–π—Å—Ç–≤–æ–º', '–ú—ã —Å—Ç–∞–ª–∫–∏–≤–∞–µ–º—Å—è —Å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å—é –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–ø–∞—Å–∞–º–∏, —á—Ç–æ–±—ã –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–¥–µ—Ä–∂–∫–∏ –∏ –ø–æ–≤—ã—Å–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –Ω–∞—à–µ–π –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Å–µ—Ç–∏', '–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º —É—á–µ—Ç–∞, –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥—É—é —Å–∏—Å—Ç–µ–º—É –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–∫—É–ø–æ–∫, –∞ —Ç–∞–∫–∂–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π, —Ç–∞–∫–∏—Ö –∫–∞–∫ RFID-–º–µ—Ç–∫–∏ –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –¥—Ä—É–≥–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏ –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏ –Ω–∞ –≤—Å–µ—Ö —ç—Ç–∞–ø–∞—Ö —Å–∫–ª–∞–¥—Å–∫–æ–≥–æ —É—á–µ—Ç–∞', '–í—Ç–æ—Ä–æ–π –≤–æ–ø—Ä–æ—Å –ø–æ–≤–µ—Å—Ç–∫–∏ –¥–Ω—è ‚Äì —ç—Ç–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–∞—à–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–æ –º–∏–Ω–æ—Ä–∏—Ç–∞—Ä–Ω—ã–º –∏ –∫—Ä—É–ø–Ω—ã–º –ø–∞—Ä—Ç–Ω—ë—Ä—Å—Ç–≤–∞–º', '–í —É—Å–ª–æ–≤–∏—è—Ö –º–µ–Ω—è—é—â–µ–≥–æ—Å—è —Ä—ã–Ω–∫–∞ –∫—Ä–∞–π–Ω–µ –≤–∞–∂–Ω–æ –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å –æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å –Ω–∞—à–∏–º–∏ —Å—Ç–æ—Ä–æ–Ω–Ω–∏–º–∏ –ø–∞—Ä—Ç–Ω–µ—Ä–∞–º–∏, –≤–æ–∑–º–æ–∂–Ω–æ, –Ω–∞–º —Å—Ç–æ–∏—Ç —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —Å–µ—Ä—å–µ–∑–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –Ω–∞—à–µ–≥–æ –ø–æ—Ä—Ç—Ñ–µ–ª—è –ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤', '–û–±—Å—É–¥–∏–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–æ—Ü–µ–Ω–∫–∏ –≤—ã–≥–æ–¥ –∏ —Ä–∏—Å–∫–æ–≤ –æ—Ç —Ç–µ–∫—É—â–∏—Ö –ø–∞—Ä—Ç–Ω—ë—Ä—Å—Ç–≤, –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –∞–ª—å—è–Ω—Å—ã, –∞ —Ç–∞–∫–∂–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–∞ —Å –Ω–∞—à–∏–º–∏ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–º–∏ –∫–æ–ª–ª–µ–≥–∞–º–∏, –¥–ª—è —á–µ–≥–æ –±—É–¥–µ—Ç –ø—Ä–æ–≤–µ–¥–µ–Ω –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –≤—ã—Ä–∞–±–æ—Ç–∞–Ω—ã –Ω–æ–≤—ã–µ –ø–æ–¥—Ö–æ–¥—ã –¥–ª—è —É—Å–∏–ª–µ–Ω–∏—è –Ω–∞—à–∏—Ö –ø–æ–∑–∏—Ü–∏–π', '–¢—Ä–µ—Ç–∏–π –ø—É–Ω–∫—Ç ‚Äì —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä–∞–±–æ—Ç—ã –æ–±—ä–µ–∫—Ç–æ–≤', '–í –Ω–∞—à–µ –≤—Ä–µ–º—è —Ü–∏—Ñ—Ä–æ–≤—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –æ—Å–Ω–æ–≤–æ–π –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏', '–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –ø–æ–∑–≤–æ–ª–∏—Ç –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–∞—à–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—Ç—å —Å–≤–æ–µ–≤—Ä–µ–º–µ–Ω–Ω—É—é —Ä–µ–∞–∫—Ü–∏—é –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö, –∞ —Ç–∞–∫–∂–µ –ø–æ–≤—ã—Å–∏—Ç—å –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –Ω–∞—à–µ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏', '–î–ª—è —ç—Ç–æ–≥–æ –Ω–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∑–∞–ª–æ–∂–µ–Ω—ã –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –∞ —Ç–∞–∫–∂–µ –≤—ã–±—Ä–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –ø–ª–∞—Ç—Ñ–æ—Ä–º—É –¥–ª—è –µ–≥–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏', '–ù–∞–∫–æ–Ω–µ—Ü, —á–µ—Ç–≤–µ—Ä—Ç–∞—è —Ç–µ–º–∞ ‚Äì –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Ü–µ–ø–æ—á–µ–∫ –ø–æ—Å—Ç–∞–≤–æ–∫', '–ú—ã —Å—Ç—Ä–µ–º–∏–º—Å—è –∫ —Ç–æ–º—É, —á—Ç–æ–±—ã –Ω–∞—à–∏ –ø–æ—Å—Ç–∞–≤–∫–∏ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–ª–∏—Å—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≥–ª–∞–¥–∫–æ –∏ —ç–∫–æ–Ω–æ–º–∏—á–Ω–æ', '–£–∂–µ —Å–µ–π—á–∞—Å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É–∑–∫–∏–µ –º–µ—Å—Ç–∞ –∏ —Å–ª–∞–±—ã–µ –∑–≤–µ–Ω—å—è –≤ –Ω–∞—à–µ–π –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ü–µ–ø–æ—á–∫–µ, —É–ª—É—á—à–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –º–∞—Ä—à—Ä—É—Ç–æ–≤, –≤–Ω–µ–¥—Ä–∏—Ç—å —Ç–µ–∫—É—â–∏–µ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏ –≤ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∫–µ, —Ç–∞–∫–∏–µ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–∏—Å—Ç–µ–º –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤ –¥–æ—Å—Ç–∞–≤–∫–∏', '–û–±—Å—É–¥–∏–º —Ç–∞–∫–∂–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –≤ –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏–∏ –≤–Ω–µ—à–Ω–∏—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é', '–ë–ª–∞–≥–æ–¥–∞—Ä—é –≤—Å–µ—Ö –∑–∞ –≤–Ω–∏–º–∞–Ω–∏–µ, –ø—Ä–µ–¥–ª–∞–≥–∞—é –ø—Ä–∏—Å—Ç—É–ø–∏—Ç—å –∫ –æ–±—Å—É–∂–¥–µ–Ω–∏—é –ø–µ—Ä–≤–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –Ω–∞—à–µ–π –ø–æ–≤–µ—Å—Ç–∫–∏.\\t']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "import re\n",
    "# Open and read the JSON file\n",
    "with open('table_dsv.json', 'r') as file:\n",
    "    test = file.readline()\n",
    "    test = re.sub('\\n', \" \", test)\n",
    "    test = re.sub(\"[!?;]\", \".\", test)\n",
    "\n",
    "print(test.split(\"suffix=\")[1].split(\"text_id\")[0].split(\". \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='result.wav'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import path \n",
    "from pydub import AudioSegment \n",
    "  \n",
    "# assign files \n",
    "input_file = \"AUDIO.mp3\"\n",
    "output_file = \"result.wav\"\n",
    "  \n",
    "# convert mp3 file to wav file \n",
    "sound = AudioSegment.from_mp3(input_file) \n",
    "sound.export(output_file, format=\"wav\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: apt-install: command not found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
